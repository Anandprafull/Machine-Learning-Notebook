# Week 2: Regression with multiple input variables

This week, you'll extend linear regression to handle multiple input features. You'll also learn some methods for improving your model's training and performance, such as vectorization, feature scaling, feature engineering and polynomial regression. At the end of the week, you'll get to practice implementing linear regression in code.

## Learning Objectives

* Use vectorization to implement multiple linear regression
* Use feature scaling, feature engineering, and polynomial regression to improve model training
* Implement linear regression in code

## Multiple linear regresion

Multiple features - Video • Duration: 9 min

Vectorization part 1 - Video • Duration: 6 min

Vectorization part 2 - Video • Duration: 6 min

Optional lab: Python, NumPy and vectorization - Lab • Duration: 1 hour1h

Gradient descent for multiple linear regression - Video • Duration: 7 min

Optional Lab: Multiple linear regression - Lab • Duration: 1 h

## Practice quiz: Multiple linear regression

Practice quiz: Multiple linear regression

## Gradient decent in practice

Feature scaling part 1 - Video • Duration: 6 min

Feature scaling part 2 - Video • Duration: 7 min

Checking gradient descent for convergence - Video • Duration: 5 min

Choosing the learning rate - Video • Duration: 6 min

Optional Lab: Feature scaling and learning rate - Lab • Duration: 1 h

Feature engineering - Video • Duration: 3  min

Polynomial regression - Video • Duration: 5  min

Optional lab: Feature engineering and Polynomial regression - Lab • Duration: 1 h

Optional lab: Linear regression with scikit-learn - Lab • Duration: 1 h

## Practice quiz: Gradient descent in practice

Practice quiz: Gradient descent in practice

## Week 2 practice lab: Linear regression

Week 2 practice lab: Linear regression - Programming Assignment • Duration: 3 h
